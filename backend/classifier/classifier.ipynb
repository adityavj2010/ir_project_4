{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "import sklearn\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import collections\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chitchat_df = pd.read_pickle(\"./chitchat.pkl\")\n",
    "chitchat_df.drop(['prompt'], axis=1, inplace=True)\n",
    "cc_new = pd.DataFrame().assign(X=chitchat_df['query'])\n",
    "cc_new[\"Y\"] = 0\n",
    "cc_new = cc_new[[\"Y\" ,\"X\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That’s what I thought. I’m sorry things haven’...</td>\n",
       "      <td>??</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nah i really don't care enough about this.</td>\n",
       "      <td>That’s what I thought. I’m sorry things haven’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Let’s hear your counter-argument then.</td>\n",
       "      <td>Nah i really don't care enough about this.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yeah i don't support the premise anyways: i do...</td>\n",
       "      <td>Let’s hear your counter-argument then.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Your premise is invalid, which invalidates you...</td>\n",
       "      <td>Yeah i don't support the premise anyways: i do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td></td>\n",
       "      <td>Check out her early stuff.  Less pop, more int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>I fucking love Shakira.  She is a national tre...</td>\n",
       "      <td>Éres de Colombia? También soy un fan de ella! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td></td>\n",
       "      <td>I fucking love Shakira.  She is a national tre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td></td>\n",
       "      <td>Well, the hips don't lie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td></td>\n",
       "      <td>She wouldn't be able to pass a fluency test fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>443146 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  query  \\\n",
       "0     That’s what I thought. I’m sorry things haven’...   \n",
       "1            Nah i really don't care enough about this.   \n",
       "2                Let’s hear your counter-argument then.   \n",
       "3     Yeah i don't support the premise anyways: i do...   \n",
       "4     Your premise is invalid, which invalidates you...   \n",
       "...                                                 ...   \n",
       "1412                                                      \n",
       "1413  I fucking love Shakira.  She is a national tre...   \n",
       "1414                                                      \n",
       "1416                                                      \n",
       "1417                                                      \n",
       "\n",
       "                                               response  \n",
       "0                                                    ??  \n",
       "1     That’s what I thought. I’m sorry things haven’...  \n",
       "2            Nah i really don't care enough about this.  \n",
       "3                Let’s hear your counter-argument then.  \n",
       "4     Yeah i don't support the premise anyways: i do...  \n",
       "...                                                 ...  \n",
       "1412  Check out her early stuff.  Less pop, more int...  \n",
       "1413  Éres de Colombia? También soy un fan de ella! ...  \n",
       "1414  I fucking love Shakira.  She is a national tre...  \n",
       "1416                          Well, the hips don't lie.  \n",
       "1417  She wouldn't be able to pass a fluency test fo...  \n",
       "\n",
       "[443146 rows x 2 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df = pd.read_pickle(\"./final.pkl\")\n",
    "reddit_df = reddit_df.loc[reddit_df['is_submission'] == False][[\"parent_body\",\"body\"]]\n",
    "reddit_df.rename(columns={\"parent_body\": \"query\", \"body\": \"response\"}, inplace=True)\n",
    "merged_qr_df = pd.concat([chitchat_df, reddit_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_new = pd.DataFrame().assign(X=reddit_df['query'])\n",
    "reddit_new[\"Y\"] = 1\n",
    "reddit_new = reddit_new[[\"Y\", \"X\"]]\n",
    "# reddit_df.loc[reddit_df['is_submission'] == False][\"body\"]\n",
    "res_df = pd.concat([reddit_new, cc_new])\n",
    "res_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>That’s what I thought. I’m sorry things haven’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Nah i really don't care enough about this.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Let’s hear your counter-argument then.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Yeah i don't support the premise anyways: i do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Your premise is invalid, which invalidates you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>1</td>\n",
       "      <td>I fucking love Shakira.  She is a national tre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>443146 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Y                                                  X\n",
       "0     1  That’s what I thought. I’m sorry things haven’...\n",
       "1     1         Nah i really don't care enough about this.\n",
       "2     1             Let’s hear your counter-argument then.\n",
       "3     1  Yeah i don't support the premise anyways: i do...\n",
       "4     1  Your premise is invalid, which invalidates you...\n",
       "...  ..                                                ...\n",
       "1412  1                                                   \n",
       "1413  1  I fucking love Shakira.  She is a national tre...\n",
       "1414  1                                                   \n",
       "1416  1                                                   \n",
       "1417  1                                                   \n",
       "\n",
       "[443146 rows x 2 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(text):    \n",
    "    text = contractions.fix(text)\n",
    "    text = text.replace(\"&gt;\", \"\")\n",
    "    text = text.replace(\"&lt;\", \"\")\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "    regex_url = r\"(http[^\\s]+)\"\n",
    "    wo_url = re.sub(regex_url,\"\",text)\n",
    "    wo_url = re.sub(r\"#\",\"\",wo_url)\n",
    "    # wo_url = re.sub(r\"(@[^\\s]+)\",\"\",wo_url)\n",
    "    wo_url = re.sub(r\"(@[^\\s]+)\",\"@USER_\",wo_url)\n",
    "\n",
    "    return wo_url\n",
    "\n",
    "\n",
    "\n",
    "res_df['X'] = res_df['X'].apply(cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_df.to_csv(r'A:\\MS2021\\SUNY BUFFALO\\Third sem\\Info Retrieval\\Project 4\\ir_project_4\\backend\\classifier\\data.csv', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "# using the low level BERT for our task.\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello</td>\n",
       "      <td>whats up MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How are you doing today?</td>\n",
       "      <td>im doing good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>whats up MD</td>\n",
       "      <td>Im alright, I just took a nap. But it was one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Im alright, I just took a nap. But it was one ...</td>\n",
       "      <td>oh wow haha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oh wow haha</td>\n",
       "      <td>Yeah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td></td>\n",
       "      <td>Check out her early stuff.  Less pop, more int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>I fucking love Shakira.  She is a national tre...</td>\n",
       "      <td>Éres de Colombia? También soy un fan de ella! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td></td>\n",
       "      <td>I fucking love Shakira.  She is a national tre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td></td>\n",
       "      <td>Well, the hips don't lie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td></td>\n",
       "      <td>She wouldn't be able to pass a fluency test fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>609314 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  query  \\\n",
       "0                                                 Hello   \n",
       "1                              How are you doing today?   \n",
       "2                                           whats up MD   \n",
       "3     Im alright, I just took a nap. But it was one ...   \n",
       "4                                           oh wow haha   \n",
       "...                                                 ...   \n",
       "1412                                                      \n",
       "1413  I fucking love Shakira.  She is a national tre...   \n",
       "1414                                                      \n",
       "1416                                                      \n",
       "1417                                                      \n",
       "\n",
       "                                               response  \n",
       "0                                           whats up MD  \n",
       "1                                         im doing good  \n",
       "2     Im alright, I just took a nap. But it was one ...  \n",
       "3                                           oh wow haha  \n",
       "4                                                  Yeah  \n",
       "...                                                 ...  \n",
       "1412  Check out her early stuff.  Less pop, more int...  \n",
       "1413  Éres de Colombia? También soy un fan de ella! ...  \n",
       "1414  I fucking love Shakira.  She is a national tre...  \n",
       "1416                          Well, the hips don't lie.  \n",
       "1417  She wouldn't be able to pass a fluency test fo...  \n",
       "\n",
       "[609314 rows x 2 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_qr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing done, now starting with classification\n",
    "------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import feature engineering modules and test_train_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "#Import classification algorithm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "#Import modules to calculate accuracy and confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAIVE BAYES CLASSIFICATION\n",
    "-----------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB(alpha=6.5, fit_prior=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=6.5, fit_prior=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB(alpha=6.5, fit_prior=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tv = TfidfVectorizer(ngram_range=(1,3),max_features=15000) \n",
    "X = tv.fit_transform(res_df['X'])\n",
    "y = res_df[\"Y\"].values\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size = 0.2, shuffle=True)\n",
    "nb = MultinomialNB(alpha=6.5, fit_prior=False)\n",
    "nb.fit(Xtrain,ytrain)\n",
    "nb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACCURACY FOR MODEL n max_features\n",
    "----------------------------------\n",
    "ACCURACY 20 - 0.6478967862235384 \n",
    "ACCURACY 40 - 0.7042064275529231\n",
    "ACCURACY 60 - 0.7171492815619173\n",
    "ACCURACY 80 - 0.7226061204343535\n",
    "ACCURACY 100 - 0.7327108698036635\n",
    "ACCURACY 120 - 0.7369885927388395\n",
    "ACCURACY 140 - 0.7538252714708786\n",
    "ACCURACY 160 - 0.7513710650433256\n",
    "ACCURACY 180 - 0.7578973346495558\n",
    "ACCURACY 200 - 0.7583497861138533\n",
    "ACCURACY 220 - 0.7634364374245914\n",
    "ACCURACY 240 - 0.7639574421410552\n",
    "ACCURACY 260 - 0.774528353625096\n",
    "ACCURACY 280 - 0.773404080289569\n",
    "ACCURACY 300 - 0.777201930459581\n",
    "ACCURACY 350 - 0.781205440386092\n",
    "ACCURACY 400 - 0.7873341011297575\n",
    "ACCURACY 450 - 0.7911867939015027\n",
    "ACCURACY 500 - 0.7937918174838214\n",
    "\n",
    "1000-1500 step50 \n",
    "[0.8115196884940221\n",
    "0.813439179554678\n",
    "0.8165926291543271\n",
    "0.817552374684655\n",
    "0.8168668421629922\n",
    "0.8146182954919381\n",
    "0.8197597894044093\n",
    "0.8182653285071844\n",
    "0.8207606668860371\n",
    "0.8221043106284962]\n",
    "\n",
    "\n",
    "5000 - 5250\n",
    "[0.6777722935176045\n",
    "0.8398458922891302\n",
    "0.839571679280465\n",
    "0.8414363277393879\n",
    "0.8435340572556762]\n",
    "\n",
    "ACCURACY 15000 - 0.8505539102775036\n",
    "---------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72936\n",
      "0.8505539102775036\n"
     ]
    }
   ],
   "source": [
    "pred = nb.predict(Xtest)\n",
    "print(accuracy_score(ytest,pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changes\n",
    "s = [{\"X\":\"How are you \"},{\"X\":\"Hi\"},{\"X\":\"Elon musk simp\"},{\"X\":\"Doland trump\"},{\"X\":\"Iphone is slow\"},{\"X\":\"I hate joe biden\"},{\"X\":\"What is Covid 19\"},{\"X\":\"What is\"},{\"X\":\"Covid 19\"},{\"X\":\"Stock market\"},{\"X\":\"Sushi sucks?\"}]\n",
    "df = pd.DataFrame(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tv = TfidfVectorizer(ngram_range=(1,3),max_features=15000) \n",
    "XDemo = tv.transform(df['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11x15000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 32 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XDemo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_preds = nb.predict(XDemo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file name, I'm using *.pickle as a file extension\n",
    "filename = \"model.pickle\"\n",
    "\n",
    "# save model\n",
    "pickle.dump(nb, open(filename, \"wb\"))\n",
    "pickle.dump(tv, open(\"tv.pickle\", \"wb\"))\n",
    "\n",
    "# load model\n",
    "# loaded_model = pickle.load(open(filename, \"rb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3e10ef16274dd72e574b8fa73b58450b957d8421a2901baded3cca26fcf5dda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
